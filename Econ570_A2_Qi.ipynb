{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648b1241",
   "metadata": {},
   "source": [
    "# ECON570 Assignment2_Qi Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f683d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz as gr\n",
    "import csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36f4f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seeds\n",
    "random.seed(100)\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa8c0c",
   "metadata": {},
   "source": [
    " ### 1. Simulate a DGP where the outcome of interest depends on a randomly assigned treatment and some observed covariates.\n",
    " ### 1.1 Simulate a DGP\n",
    " $y_i = \\alpha + \\tau*T_i+ \\beta*X + e_i$\n",
    "\n",
    "$e_i \\sim N(0,\\sigma^2)$\n",
    "\n",
    "where \n",
    "$\\alpha$ is the intercept; $\\tau$ is the treatment effect; T is the treatment;  $\\beta$ is the coefficients on covariate; X is the covariate; e is the disturbance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ebb498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=2\n",
    "tau = 3\n",
    "beta=2\n",
    "n=100\n",
    "corr = .5\n",
    "conf = False\n",
    "T= np.random.normal(0,1,n)\n",
    "X = np.random.uniform(0,0.5,n)\n",
    "e = np.random.normal(0,10,n)\n",
    "Y = 2+ 3* T + 2*X +e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8705f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.DataFrame(dict(Y = Y,\n",
    "                           Treatment = T,\n",
    "                           X = X))\n",
    "#output the dataset\n",
    "data_1.to_csv('data_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afabf537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.108428</td>\n",
       "      <td>-1.749765</td>\n",
       "      <td>0.201440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.285076</td>\n",
       "      <td>0.342680</td>\n",
       "      <td>0.177149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.189700</td>\n",
       "      <td>1.153036</td>\n",
       "      <td>0.250307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.524414</td>\n",
       "      <td>-0.252436</td>\n",
       "      <td>0.222588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.876232</td>\n",
       "      <td>0.981321</td>\n",
       "      <td>0.045216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>10.782577</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>0.271140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2.106113</td>\n",
       "      <td>-0.076023</td>\n",
       "      <td>0.041132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17.822871</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.317818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.937474</td>\n",
       "      <td>-0.185014</td>\n",
       "      <td>0.398203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-9.313029</td>\n",
       "      <td>-2.487152</td>\n",
       "      <td>0.477374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y  Treatment         X\n",
       "0   -4.108428  -1.749765  0.201440\n",
       "1   23.285076   0.342680  0.177149\n",
       "2   11.189700   1.153036  0.250307\n",
       "3    1.524414  -0.252436  0.222588\n",
       "4    0.876232   0.981321  0.045216\n",
       "..        ...        ...       ...\n",
       "95  10.782577   0.003017  0.271140\n",
       "96   2.106113  -0.076023  0.041132\n",
       "97  17.822871   0.003958  0.317818\n",
       "98   5.937474  -0.185014  0.398203\n",
       "99  -9.313029  -2.487152  0.477374\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e3400",
   "metadata": {},
   "source": [
    "### 1.2 Illustrate your DGP with a DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d17b16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (20211204.2007)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"220pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 219.84 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 215.84,-112 215.84,4 -4,4\"/>\n",
       "<!-- Treatment -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Treatment</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"47.45\" cy=\"-90\" rx=\"47.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.45\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Treatment</text>\n",
       "</g>\n",
       "<!-- Outcome(Y) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Outcome(Y)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"104.45\" cy=\"-18\" rx=\"56.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"104.45\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outcome(Y)</text>\n",
       "</g>\n",
       "<!-- Treatment&#45;&gt;Outcome(Y) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Treatment&#45;&gt;Outcome(Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M60.95,-72.41C67.88,-63.91 76.46,-53.37 84.16,-43.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.04,-45.92 90.64,-35.96 81.61,-41.5 87.04,-45.92\"/>\n",
       "</g>\n",
       "<!-- Covariates -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Covariates</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"162.45\" cy=\"-90\" rx=\"49.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.45\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Covariates</text>\n",
       "</g>\n",
       "<!-- Covariates&#45;&gt;Outcome(Y) -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Covariates&#45;&gt;Outcome(Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.7,-72.41C141.48,-63.69 132.49,-52.85 124.5,-43.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"127.17,-40.94 118.09,-35.47 121.78,-45.4 127.17,-40.94\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1834e991190>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_1 = gr.Digraph()\n",
    "g_1.edge(\"Treatment\", \"Outcome(Y)\")\n",
    "g_1.edge(\"Covariates\", \"Outcome(Y)\")\n",
    "g_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075d5e7",
   "metadata": {},
   "source": [
    "### 1.3 Monte Carlo experiment\n",
    "#### a. not control for any covariates\n",
    "\n",
    "$y_i = \\alpha +\\tau*T_i+e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd91f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function\n",
    "def fn_generate_data(tau,N,p,p0,corr,conf = False,flagX = False):\n",
    "    nvar = p+2\n",
    "    corr = 0.5 \n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 \n",
    "    \n",
    "    else:\n",
    "        conf_mult = 1\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) \n",
    "    C = allX[:,1].reshape([N,1]) \n",
    "    X = allX[:,2:] \n",
    "    \n",
    "    T = fn_randomize_treatment(N) \n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0\n",
    "    Yab = tau*T+X@beta0+err\n",
    "    if flagX==False:\n",
    "        return (Yab,T)\n",
    "    else:\n",
    "        return (Yab,T,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d2e61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "587792b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_cov(dim):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "  \n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34e7d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    " \n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "   \n",
    "    return (bias,rmse,size)\n",
    "\n",
    "def fn_tauhat_means(Yt,Yc):\n",
    "    nt = len(Yt)\n",
    "    nc = len(Yc)\n",
    "    tauhat = np.mean(Yt)-np.mean(Yc)\n",
    "    se_tauhat = (np.var(Yt,ddof=1)/nt+np.var(Yc,ddof=1)/nc)**(1/2)\n",
    "    return (tauhat,se_tauhat)\n",
    "\n",
    "def fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX=False):\n",
    "    n_values = []\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    lb = []\n",
    "    ub = []\n",
    "    for N in tqdm(Nrange):\n",
    "        n_values = n_values + [N]\n",
    "        if flagX==False:\n",
    "            Yexp,T = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Yt = Yexp[np.where(T==1)[0],:]\n",
    "            Yc = Yexp[np.where(T==0)[0],:]\n",
    "            tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)            \n",
    "        elif flagX==1:\n",
    "           \n",
    "            Yexp,T,X = fn_generate_data(tau,N,p,p0,corr,conf,flagX)\n",
    "            Xobs = X[:,:p0]\n",
    "            covars = np.concatenate([T,Xobs],axis = 1)\n",
    "            mod = sm.OLS(Yexp,covars)\n",
    "            res = mod.fit()\n",
    "            tauhat = res.params[0]\n",
    "            se_tauhat = res.HC1_se[0]\n",
    "\n",
    "            \n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]    \n",
    "        lb = lb + [tauhat-1.96*se_tauhat]\n",
    "        ub = ub + [tauhat+1.96*se_tauhat]\n",
    "        \n",
    "    return (n_values,tauhats,sehats,lb,ub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d75ced50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3246.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 250.03it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T = fn_generate_data(tau,N,5,0,corr,conf)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea119573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.006374096336077445, RMSE=0.20457678231004428, size=0.054\n",
      "N=1000: bias=0.0013170270394993935, RMSE=0.06435652455507904, size=0.045\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c36f520",
   "metadata": {},
   "source": [
    "#### b. control for all the covariates that affect the outcome\n",
    "\n",
    "$y_i = \\alpha + \\tau*T_i+ \\beta*X + e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "053ea452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 450/450 [00:02<00:00, 162.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Use same DGP as case a\n",
    "tau = 2\n",
    "corr = .5\n",
    "conf=False\n",
    "p = 100\n",
    "p0 = 1\n",
    "Nrange = range(100,1000,2) \n",
    "\n",
    "flagX = 1\n",
    "(nvalues2,tauhats2,sehats2,lb2,ub2) = fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c850e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1692.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 190.22it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data(tau,N,5,1,corr,conf,flagX)\n",
    "        Xobs = X[:,:p0]\n",
    "        covars = np.concatenate([T,Xobs],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_ahat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dc3e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.0011218141323538152, RMSE=0.14521905977377048, size=0.385\n",
      "N=1000: bias=-0.00015183476507183525, RMSE=0.04575924224420856, size=0.009\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8050733",
   "metadata": {},
   "source": [
    "From the output of case A and caseB, we find that controlling covariates could enhance the estimator which performs better for the bias,RMSE and size of your treatment effect estimate(both N=100 and N=10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000bb03",
   "metadata": {},
   "source": [
    "### 1.4 an example of a real-life situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322960d3",
   "metadata": {},
   "source": [
    "When we want to know the effect of temperature on precipitation, but altitude, latitude and longitude, local humidity and other variables may also affect precipitation.In this case, temperature is the independent variable, precipitation is the dependent variable, and altitude, latitude and longitude and local humidity are the covariables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6c198",
   "metadata": {},
   "source": [
    "## 2. Simulate a DGP with a confounder.\n",
    "### 2.1 Simulate a DGP\n",
    "$y_i = \\alpha +\\tau*T_i+ \\beta*X + 0.4* C + e_i $\n",
    "\n",
    "\n",
    "where  C is the confounder,  T is the treatment;   𝜏  is the treatment effect; 𝛼  is the intercept; 𝛽  is the coefficients on covariate; X is the covariate; e is the disturbance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c9125ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=2\n",
    "tau = 3\n",
    "beta=2\n",
    "n=100\n",
    "corr = .5\n",
    "conf = False\n",
    "T= np.random.normal(0,1,n)\n",
    "X = np.random.uniform(0,0.5,n)\n",
    "C = np.random.normal(0,1,n)\n",
    "e = np.random.normal(0,10,n)\n",
    "Y = 2+ 3* T + 2*X + 0.6 * C+ e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d581f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.DataFrame(dict(Y = Y,\n",
    "                           Treatment = T,\n",
    "                           Confounder = C,\n",
    "                           X = X))\n",
    "#output the dataset\n",
    "data_2.to_csv('data_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fc72846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Confounder</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.408668</td>\n",
       "      <td>-0.159633</td>\n",
       "      <td>-1.388541</td>\n",
       "      <td>0.029209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.813386</td>\n",
       "      <td>1.815076</td>\n",
       "      <td>1.534360</td>\n",
       "      <td>0.154235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.596936</td>\n",
       "      <td>0.675753</td>\n",
       "      <td>-0.316069</td>\n",
       "      <td>0.269878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.923134</td>\n",
       "      <td>2.363238</td>\n",
       "      <td>0.626968</td>\n",
       "      <td>0.273630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.932523</td>\n",
       "      <td>1.928127</td>\n",
       "      <td>-0.076412</td>\n",
       "      <td>0.310560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-2.006903</td>\n",
       "      <td>-0.347429</td>\n",
       "      <td>-1.100627</td>\n",
       "      <td>0.402572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>15.137777</td>\n",
       "      <td>-0.699776</td>\n",
       "      <td>0.093098</td>\n",
       "      <td>0.427418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-10.029119</td>\n",
       "      <td>-1.901757</td>\n",
       "      <td>0.871639</td>\n",
       "      <td>0.469689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-5.886589</td>\n",
       "      <td>-0.308278</td>\n",
       "      <td>-0.868286</td>\n",
       "      <td>0.247962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>14.062322</td>\n",
       "      <td>-0.294403</td>\n",
       "      <td>1.177898</td>\n",
       "      <td>0.102028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y  Treatment  Confounder         X\n",
       "0   -2.408668  -0.159633   -1.388541  0.029209\n",
       "1    8.813386   1.815076    1.534360  0.154235\n",
       "2   16.596936   0.675753   -0.316069  0.269878\n",
       "3   14.923134   2.363238    0.626968  0.273630\n",
       "4   -5.932523   1.928127   -0.076412  0.310560\n",
       "..        ...        ...         ...       ...\n",
       "95  -2.006903  -0.347429   -1.100627  0.402572\n",
       "96  15.137777  -0.699776    0.093098  0.427418\n",
       "97 -10.029119  -1.901757    0.871639  0.469689\n",
       "98  -5.886589  -0.308278   -0.868286  0.247962\n",
       "99  14.062322  -0.294403    1.177898  0.102028\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9c26c",
   "metadata": {},
   "source": [
    "### 2.2 Illustrate your DGP with a DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c898dcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (20211204.2007)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"150pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 149.99 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 145.99,-184 145.99,4 -4,4\"/>\n",
       "<!-- Confounder -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Confounder</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"56.54\" cy=\"-162\" rx=\"54.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.54\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Confounder</text>\n",
       "</g>\n",
       "<!-- Outcome(Y) -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Outcome(Y)</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"56.54\" cy=\"-18\" rx=\"56.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.54\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outcome(Y)</text>\n",
       "</g>\n",
       "<!-- Confounder&#45;&gt;Outcome(Y) -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Confounder&#45;&gt;Outcome(Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49.07,-143.7C45.07,-133.52 40.57,-120.27 38.54,-108 35.94,-92.21 35.94,-87.79 38.54,-72 39.99,-63.28 42.68,-54.06 45.55,-45.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"48.88,-46.89 49.07,-36.3 42.31,-44.46 48.88,-46.89\"/>\n",
       "</g>\n",
       "<!-- Treatment -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Treatment</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"94.54\" cy=\"-90\" rx=\"47.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"94.54\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Treatment</text>\n",
       "</g>\n",
       "<!-- Confounder&#45;&gt;Treatment -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Confounder&#45;&gt;Treatment</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65.74,-144.05C70.18,-135.89 75.59,-125.91 80.53,-116.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.74,-118.25 85.43,-107.79 77.58,-114.91 83.74,-118.25\"/>\n",
       "</g>\n",
       "<!-- Treatment&#45;&gt;Outcome(Y) -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Treatment&#45;&gt;Outcome(Y)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M85.35,-72.05C80.91,-63.89 75.5,-53.91 70.56,-44.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.51,-42.91 65.66,-35.79 67.35,-46.25 73.51,-42.91\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1834f52f2e0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_2 = gr.Digraph()\n",
    "\n",
    "g_2.edge(\"Confounder\", \"Outcome(Y)\")\n",
    "g_2.edge(\"Confounder\", \"Treatment\")\n",
    "g_2.edge(\"Treatment\", \"Outcome(Y)\")\n",
    "g_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327647ac",
   "metadata": {},
   "source": [
    "### 2.3 Monte Carlo experiment\n",
    "#### a. fail to control for the confounder\n",
    "\n",
    "$y_i = \\alpha + \\tau*T_i+ \\beta*X + e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9bafe4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data_conf(tau,N,p,p0,corr,conf = True):\n",
    "   \n",
    "    nvar = p+2 \n",
    "    corr = 0.5 \n",
    "\n",
    "    if conf==False:\n",
    "        conf_mult = 0 \n",
    "    \n",
    "    else:\n",
    "        conf_mult = 1\n",
    "        \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allX[:,0].reshape([N,1]) \n",
    "    C = allX[:,1].reshape([N,1]) \n",
    "    X = allX[:,2:]\n",
    "    \n",
    "    T = fn_randomize_treatment(N) \n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1])\n",
    "    \n",
    "    beta0[p0:p] = 0 \n",
    "    Yab = tau*T+X@beta0+conf_mult*0.4*C+err\n",
    "        \n",
    "    return (Yab,T,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a279b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 450/450 [00:01<00:00, 422.93it/s]\n"
     ]
    }
   ],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf= False\n",
    "p = 5\n",
    "p0 = 1 #\n",
    "Nrange = range(100,1000,2) \n",
    "\n",
    "flagX = 1\n",
    "(nvalues2,tauhats2,sehats2,lb2,ub2) = fn_run_experiments(tau,Nrange,p,p0,corr,conf,flagX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88091587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1739.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 190.55it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data_conf(tau,N,5,1,corr,conf)\n",
    "        Xobs = X[:,:p0]\n",
    "        covars = np.concatenate([T,Xobs],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_ahat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86aa7cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.00409461030451784, RMSE=0.1415404219037701, size=0.369\n",
      "N=1000: bias=0.0002343495287401296, RMSE=0.04561170575769043, size=0.006\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb81a2f",
   "metadata": {},
   "source": [
    "#### b. control for the confounder\n",
    "\n",
    "$y_i = \\alpha +\\tau*T_i+ \\beta*X + 0.4* C + e_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "88bd9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 2\n",
    "corr = .5\n",
    "conf= True\n",
    "p = 5\n",
    "p0 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6b561890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1566.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:05<00:00, 175.71it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Y,T,X = fn_generate_data_conf(tau,N,5,1,corr,conf)\n",
    "        Xobs = X[:,:p0]\n",
    "        covars = np.concatenate([T,Xobs],axis = 1)\n",
    "        mod = sm.OLS(Y,covars)\n",
    "        res = mod.fit()\n",
    "        tauhat = res.params[0]\n",
    "        se_ahat = res.HC1_se[0]\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "        \n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f149c5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.010895223067282987, RMSE=0.1647760682025798, size=0.435\n",
      "N=1000: bias=-0.0008890105873970033, RMSE=0.04953177857308198, size=0.014\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434a4a79",
   "metadata": {},
   "source": [
    "### 2.4 an example of a real-life situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac8e3b",
   "metadata": {},
   "source": [
    "When we want to determine how long a week of physical activity affected physical fitness, we should consider the confounder. The treatment is exercise time, the outcome is physical fitness, and the confounder is Age. \n",
    "\n",
    "When we do not consider the confounder, we may get the conclusion that the longer you exercise, the worse your health. However, after group by age, we can get that the exercise time and physical health degree in each age group are positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57b520",
   "metadata": {},
   "source": [
    "## 3.Simulate a DGP with selection bias into the treatment\n",
    "### 3.1 Simulate a DGP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71a3120",
   "metadata": {},
   "source": [
    "$y_i = \\tau*T_i+e_i$\n",
    "\n",
    "$Z_i = \\beta*T_i+e_i$ \n",
    "\n",
    "After considering the selection bias, the model would be:\n",
    "\n",
    "$y_i = \\tau *T_i+ \\lambda*Z_i + e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3be21d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 3\n",
    "lambda_z = .5\n",
    "beta = 2\n",
    "N = 100\n",
    "conts = True\n",
    "\n",
    "T= np.random.normal(0,1,n)\n",
    "Y=3*T + e\n",
    "Z= 2*T +e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "adc434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = pd.DataFrame(dict(Y = Y,\n",
    "                           Treatment = T,\n",
    "                           Z = Z))\n",
    "#output the dataset\n",
    "data_3.to_csv('data_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d6378c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.190132</td>\n",
       "      <td>-0.345023</td>\n",
       "      <td>-3.845108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.169272</td>\n",
       "      <td>1.343400</td>\n",
       "      <td>2.825872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.041235</td>\n",
       "      <td>0.607224</td>\n",
       "      <td>13.434011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.945259</td>\n",
       "      <td>-0.321574</td>\n",
       "      <td>4.266832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-16.733366</td>\n",
       "      <td>-0.813729</td>\n",
       "      <td>-15.919636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.909846</td>\n",
       "      <td>1.339744</td>\n",
       "      <td>-0.429898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>17.560879</td>\n",
       "      <td>1.078156</td>\n",
       "      <td>16.482722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-11.011208</td>\n",
       "      <td>-1.074999</td>\n",
       "      <td>-9.936209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-7.684979</td>\n",
       "      <td>-0.249424</td>\n",
       "      <td>-7.435555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>15.929801</td>\n",
       "      <td>1.298354</td>\n",
       "      <td>14.631446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y  Treatment          Z\n",
       "0   -4.190132  -0.345023  -3.845108\n",
       "1    4.169272   1.343400   2.825872\n",
       "2   14.041235   0.607224  13.434011\n",
       "3    3.945259  -0.321574   4.266832\n",
       "4  -16.733366  -0.813729 -15.919636\n",
       "..        ...        ...        ...\n",
       "95   0.909846   1.339744  -0.429898\n",
       "96  17.560879   1.078156  16.482722\n",
       "97 -11.011208  -1.074999  -9.936209\n",
       "98  -7.684979  -0.249424  -7.435555\n",
       "99  15.929801   1.298354  14.631446\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ac0d0",
   "metadata": {},
   "source": [
    "### 3.2 Illustrate your DGP with a DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0db653b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (20211204.2007)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- Z -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Z</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Z</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Z -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;Z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29\"/>\n",
       "</g>\n",
       "<!-- Z&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Z&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1834e988610>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_3 = gr.Digraph()\n",
    "g_3.edge(\"T\", \"Z\")\n",
    "g_3.edge(\"T\", \"Y\")\n",
    "g_3.edge(\"Z\", \"Y\")\n",
    "g_3.node(\"Z\", \"Z\")\n",
    "g_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ee6c22",
   "metadata": {},
   "source": [
    "### 3.3 Monte Carlo experiment\n",
    "#### a.control for the variable in between the path from cause to effect\n",
    "$y_i = \\tau *T_i+ \\lambda*Z_i + e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "68beddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_generate_data_bias(tau,N,beta,lambda_z,conts):\n",
    " \n",
    "    nvar = p+1 #1 bias\n",
    "    corr = 0.5 \n",
    "        \n",
    "    allZ = fn_generate_multnorm(N,corr,nvar)\n",
    "    W0 = allZ[:,0].reshape([N,1]) \n",
    "    C = allZ[:,1].reshape([N,1]) \n",
    "    Z = allZ[:,2:] \n",
    "    \n",
    "    T = fn_randomize_treatment(N)\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    \n",
    "    Y = tau*T+lambda_z*Z+err\n",
    "        \n",
    "    return (Y,T,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a934fe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3468.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 253.38it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T,X = fn_generate_data_bias(tau,N,2,0.5,conts)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4d1f8cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.00609209378976346, RMSE=0.21663110363839333, size=0.049\n",
      "N=1000: bias=0.0018189210755674581, RMSE=0.0691420841803865, size=0.046\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874472f2",
   "metadata": {},
   "source": [
    "#### b. not control for the variable in between the path from cause to effect\n",
    "$y_i = \\tau*T_i+e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1e68e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3471.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 253.63it/s]\n"
     ]
    }
   ],
   "source": [
    "estDict = {}\n",
    "R = 1000\n",
    "for N in [100,1000]:\n",
    "    tauhats = []\n",
    "    sehats = []\n",
    "    for r in tqdm(range(R)):\n",
    "        Yexp,T,X = fn_generate_data_bias(tau,N,0,0,conts)\n",
    "        Yt = Yexp[np.where(T==1)[0],:]\n",
    "        Yc = Yexp[np.where(T==0)[0],:]\n",
    "        tauhat,se_tauhat = fn_tauhat_means(Yt,Yc)\n",
    "        tauhats = tauhats + [tauhat]\n",
    "        sehats = sehats + [se_tauhat]\n",
    "    estDict[N] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "113d2ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=-0.004979683674327243, RMSE=0.20144149072604386, size=0.057\n",
      "N=1000: bias=-0.0021921779418158853, RMSE=0.06271405816830024, size=0.052\n"
     ]
    }
   ],
   "source": [
    "tau0 = tau*np.ones([R,1])\n",
    "for N, results in estDict.items():\n",
    "    (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                         results['sehat'])\n",
    "    print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329dcd2",
   "metadata": {},
   "source": [
    "### 3.4 an example of a real-life situation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255cdd74",
   "metadata": {},
   "source": [
    "When we study the learning situation of college students in USA, if the sample space is only Top30 university , there will certainly be a great difference in the overall survey results, which is selection bias. In the random variable experiment, the error of the sample we choose is very large and cannot represent the whole, which leads to selection bias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
